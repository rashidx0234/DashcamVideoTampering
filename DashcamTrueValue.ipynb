{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a53fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "filename = 'model5.sav'\n",
    "path = \"C:/Users/hpvic/Python/noise/\"\n",
    "\n",
    "loaded_model = joblib.load(path + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4875284e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Submitted: Iphone.MOV\n",
      "Total frames in the video submitted: 3648\n",
      "Test Images length: 10\n",
      "Image 1\n",
      "This image is in class: SamsungA23\n",
      "---\n",
      "Image 2\n",
      "This image is in class: Iphone12ProMax\n",
      "---\n",
      "Image 3\n",
      "This image is in class: Iphone12ProMax\n",
      "---\n",
      "Image 4\n",
      "This image is in class: SamsungA23\n",
      "---\n",
      "Image 5\n",
      "This image is in class: Iphone12ProMax\n",
      "---\n",
      "Image 6\n",
      "This image is in class: Iphone12ProMax\n",
      "---\n",
      "Image 7\n",
      "This image is in class: Iphone12ProMax\n",
      "---\n",
      "Image 8\n",
      "This image is in class: Iphone12ProMax\n",
      "---\n",
      "Image 9\n",
      "This image is in class: Iphone12ProMax\n",
      "---\n",
      "Image 10\n",
      "This image is in class: Iphone12ProMax\n",
      "---\n",
      "\n",
      "Overall class of the video: Iphone12ProMax\n"
     ]
    }
   ],
   "source": [
    "testImages = []\n",
    "predictions = []\n",
    "\n",
    "video_path = \"C:/Users/hpvic/Python/VideoForgery/UnseenData/Iphone.MOV\"\n",
    "vidcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "video_filename = os.path.basename(video_path) \n",
    "print(\"Video Submitted:\", video_filename)  # Display the video path\n",
    "\n",
    "frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"Total frames in the video submitted:\", frameCount) # Display total number of frames\n",
    "frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Select 10 random frame indices\n",
    "randomFrameIndices = randbvcom.sample(range(frameCount), 10)\n",
    "\n",
    "for frameIndex in sorted(randomFrameIndices):\n",
    "    # Set the position of the video to the start of the frame\n",
    "    vidcap.set(cv2.CAP_PROP_POS_FRAMES, frameIndex)\n",
    "\n",
    "    # Read the frame\n",
    "    success, image = vidcap.read()\n",
    "    if not success:\n",
    "        print(\"Error reading frame.\")\n",
    "        continue\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.resize(image, (1920, 1080), interpolation=cv2.INTER_LINEAR)\n",
    "    image = cv2.fastNlMeansDenoising(image, None, 10, 7, 21)\n",
    "\n",
    "    # Append the image to the testImages array\n",
    "    testImages.append(image)\n",
    "\n",
    "# Print the lengths of the arrays to verify\n",
    "print(\"Test Images length:\", len(testImages))\n",
    "\n",
    "combine = np.array(testImages)\n",
    "\n",
    "combine = combine.reshape(combine.shape[0], combine.shape[1] * combine.shape[2])\n",
    "\n",
    "for i in range(len(combine)):\n",
    "    result = loaded_model.predict([combine[i]])\n",
    "    dictionary = {\n",
    "        0: \"70mai A400s\",\n",
    "        1: \"70mai A500s\",\n",
    "        2: \"A800s\",\n",
    "        3: \"D08\",\n",
    "        4: \"HuaweiNova3i\",\n",
    "        5: \"Iphone12ProMax\",\n",
    "        6: \"N3Pro\",\n",
    "        7: \"SamsungA23\",\n",
    "        8: \"Z40\"\n",
    "    }\n",
    "    for key, value in dictionary.items():\n",
    "        if key == result[0]:\n",
    "            result = value\n",
    "    \n",
    "    predictions.append(result)\n",
    "    \n",
    "    print(\"Image\", i + 1)\n",
    "    print(\"This image is in class:\", result)\n",
    "    print(\"---\")\n",
    "    \n",
    "most_common_prediction = Counter(predictions).most_common(1)[0][0]\n",
    "print(\"\\nOverall class of the video:\", most_common_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8eb9a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Submitted: SamsungA23.mp4\n",
      "Total frames in the video submitted: 350\n",
      "Test Images length: 10\n",
      "Image 1\n",
      "This image is in class: SamsungA23\n",
      "---\n",
      "Image 2\n",
      "This image is in class: SamsungA23\n",
      "---\n",
      "Image 3\n",
      "This image is in class: SamsungA23\n",
      "---\n",
      "Image 4\n",
      "This image is in class: SamsungA23\n",
      "---\n",
      "Image 5\n",
      "This image is in class: SamsungA23\n",
      "---\n",
      "Image 6\n",
      "This image is in class: SamsungA23\n",
      "---\n",
      "Image 7\n",
      "This image is in class: SamsungA23\n",
      "---\n",
      "Image 8\n",
      "This image is in class: SamsungA23\n",
      "---\n",
      "Image 9\n",
      "This image is in class: SamsungA23\n",
      "---\n",
      "Image 10\n",
      "This image is in class: SamsungA23\n",
      "---\n",
      "\n",
      "Overall class of the video: SamsungA23\n"
     ]
    }
   ],
   "source": [
    "testImages = []\n",
    "predictions = []\n",
    "\n",
    "video_path = \"C:/Users/hpvic/Python/VideoForgery/UnseenData/SamsungA23.mp4\"\n",
    "vidcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "video_filename = os.path.basename(video_path) \n",
    "print(\"Video Submitted:\", video_filename)  # Display the video path\n",
    "\n",
    "frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"Total frames in the video submitted:\", frameCount) # Display total number of frames\n",
    "frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Select 10 random frame indices\n",
    "randomFrameIndices = random.sample(range(frameCount), 10)\n",
    "\n",
    "for frameIndex in sorted(randomFrameIndices):\n",
    "    # Set the position of the video to the start of the frame\n",
    "    vidcap.set(cv2.CAP_PROP_POS_FRAMES, frameIndex)\n",
    "\n",
    "    # Read the frame\n",
    "    success, image = vidcap.read()\n",
    "    if not success:\n",
    "        print(\"Error reading frame.\")\n",
    "        continue\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.resize(image, (1920, 1080), interpolation=cv2.INTER_LINEAR)\n",
    "    image = cv2.fastNlMeansDenoising(image, None, 10, 7, 21)\n",
    "\n",
    "    # Append the image to the testImages array\n",
    "    testImages.append(image)\n",
    "\n",
    "# Print the lengths of the arrays to verify\n",
    "print(\"Test Images length:\", len(testImages))\n",
    "\n",
    "combine = np.array(testImages)\n",
    "\n",
    "combine = combine.reshape(combine.shape[0], combine.shape[1] * combine.shape[2])\n",
    "\n",
    "for i in range(len(combine)):\n",
    "    result = loaded_model.predict([combine[i]])\n",
    "    dictionary = {\n",
    "        0: \"70mai A400s\",\n",
    "        1: \"70mai A500s\",\n",
    "        2: \"A800s\",\n",
    "        3: \"D08\",\n",
    "        4: \"HuaweiNova3i\",\n",
    "        5: \"Iphone12ProMax\",\n",
    "        6: \"N3Pro\",\n",
    "        7: \"SamsungA23\",\n",
    "        8: \"Z40\"\n",
    "    }\n",
    "    for key, value in dictionary.items():\n",
    "        if key == result[0]:\n",
    "            result = value\n",
    "    \n",
    "    predictions.append(result)\n",
    "    \n",
    "    print(\"Image\", i + 1)\n",
    "    print(\"This image is in class:\", result)\n",
    "    print(\"---\")\n",
    "    \n",
    "most_common_prediction = Counter(predictions).most_common(1)[0][0]\n",
    "print(\"\\nOverall class of the video:\", most_common_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c145b84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Submitted: 70maiA400.mp4\n",
      "Total frames in the video submitted: 5400\n",
      "Test Images length: 10\n",
      "Image 1\n",
      "This image is in class: 70mai A400s\n",
      "---\n",
      "Image 2\n",
      "This image is in class: 70mai A400s\n",
      "---\n",
      "Image 3\n",
      "This image is in class: 70mai A400s\n",
      "---\n",
      "Image 4\n",
      "This image is in class: 70mai A400s\n",
      "---\n",
      "Image 5\n",
      "This image is in class: 70mai A400s\n",
      "---\n",
      "Image 6\n",
      "This image is in class: 70mai A400s\n",
      "---\n",
      "Image 7\n",
      "This image is in class: 70mai A400s\n",
      "---\n",
      "Image 8\n",
      "This image is in class: 70mai A400s\n",
      "---\n",
      "Image 9\n",
      "This image is in class: 70mai A400s\n",
      "---\n",
      "Image 10\n",
      "This image is in class: 70mai A400s\n",
      "---\n",
      "\n",
      "Overall class of the video: 70mai A400s\n"
     ]
    }
   ],
   "source": [
    "testImages = []\n",
    "predictions = []\n",
    "\n",
    "video_path = \"C:/Users/hpvic/Python/VideoForgery/UnseenData/70maiA400.mp4\"\n",
    "vidcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "video_filename = os.path.basename(video_path) \n",
    "print(\"Video Submitted:\", video_filename)  # Display the video path\n",
    "\n",
    "frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"Total frames in the video submitted:\", frameCount) # Display total number of frames\n",
    "frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Select 10 random frame indices\n",
    "randomFrameIndices = random.sample(range(frameCount), 10)\n",
    "\n",
    "for frameIndex in sorted(randomFrameIndices):\n",
    "    # Set the position of the video to the start of the frame\n",
    "    vidcap.set(cv2.CAP_PROP_POS_FRAMES, frameIndex)\n",
    "\n",
    "    # Read the frame\n",
    "    success, image = vidcap.read()\n",
    "    if not success:\n",
    "        print(\"Error reading frame.\")\n",
    "        continue\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.resize(image, (1920, 1080), interpolation=cv2.INTER_LINEAR)\n",
    "    image = cv2.fastNlMeansDenoising(image, None, 10, 7, 21)\n",
    "\n",
    "    # Append the image to the testImages array\n",
    "    testImages.append(image)\n",
    "\n",
    "# Print the lengths of the arrays to verify\n",
    "print(\"Test Images length:\", len(testImages))\n",
    "\n",
    "combine = np.array(testImages)\n",
    "\n",
    "combine = combine.reshape(combine.shape[0], combine.shape[1] * combine.shape[2])\n",
    "\n",
    "for i in range(len(combine)):\n",
    "    result = loaded_model.predict([combine[i]])\n",
    "    dictionary = {\n",
    "        0: \"70mai A400s\",\n",
    "        1: \"70mai A500s\",\n",
    "        2: \"A800s\",\n",
    "        3: \"D08\",\n",
    "        4: \"HuaweiNova3i\",\n",
    "        5: \"Iphone12ProMax\",\n",
    "        6: \"N3Pro\",\n",
    "        7: \"SamsungA23\",\n",
    "        8: \"Z40\"\n",
    "    }\n",
    "    for key, value in dictionary.items():\n",
    "        if key == result[0]:\n",
    "            result = value\n",
    "    \n",
    "    predictions.append(result)\n",
    "    \n",
    "    print(\"Image\", i + 1)\n",
    "    print(\"This image is in class:\", result)\n",
    "    print(\"---\")\n",
    "    \n",
    "most_common_prediction = Counter(predictions).most_common(1)[0][0]\n",
    "print(\"\\nOverall class of the video:\", most_common_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd59cecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Submitted: unknown.mp4\n",
      "Total frames in the video submitted: 825\n",
      "Test Images length: 10\n",
      "Image 1\n",
      "This image is in class: SamsungA23\n",
      "---\n",
      "Image 2\n",
      "This image is in class: 70mai A500s\n",
      "---\n",
      "Image 3\n",
      "This image is in class: 70mai A500s\n",
      "---\n",
      "Image 4\n",
      "This image is in class: SamsungA23\n",
      "---\n",
      "Image 5\n",
      "This image is in class: SamsungA23\n",
      "---\n",
      "Image 6\n",
      "This image is in class: SamsungA23\n",
      "---\n",
      "Image 7\n",
      "This image is in class: SamsungA23\n",
      "---\n",
      "Image 8\n",
      "This image is in class: SamsungA23\n",
      "---\n",
      "Image 9\n",
      "This image is in class: SamsungA23\n",
      "---\n",
      "Image 10\n",
      "This image is in class: SamsungA23\n",
      "---\n",
      "\n",
      "Overall class of the video: SamsungA23\n"
     ]
    }
   ],
   "source": [
    "testImages = []\n",
    "predictions = []\n",
    "\n",
    "video_path = \"C:/Users/hpvic/Python/VideoForgery/UnseenData/unknown.mp4\"\n",
    "vidcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "video_filename = os.path.basename(video_path) \n",
    "print(\"Video Submitted:\", video_filename)  # Display the video path\n",
    "\n",
    "frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"Total frames in the video submitted:\", frameCount) # Display total number of frames\n",
    "frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Select 10 random frame indices\n",
    "randomFrameIndices = random.sample(range(frameCount), 10)\n",
    "\n",
    "for frameIndex in sorted(randomFrameIndices):\n",
    "    # Set the position of the video to the start of the frame\n",
    "    vidcap.set(cv2.CAP_PROP_POS_FRAMES, frameIndex)\n",
    "\n",
    "    # Read the frame\n",
    "    success, image = vidcap.read()\n",
    "    if not success:\n",
    "        print(\"Error reading frame.\")\n",
    "        continue\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.resize(image, (1920, 1080), interpolation=cv2.INTER_LINEAR)\n",
    "    image = cv2.fastNlMeansDenoising(image, None, 10, 7, 21)\n",
    "\n",
    "    # Append the image to the testImages array\n",
    "    testImages.append(image)\n",
    "\n",
    "# Print the lengths of the arrays to verify\n",
    "print(\"Test Images length:\", len(testImages))\n",
    "\n",
    "combine = np.array(testImages)\n",
    "\n",
    "combine = combine.reshape(combine.shape[0], combine.shape[1] * combine.shape[2])\n",
    "\n",
    "for i in range(len(combine)):\n",
    "    result = loaded_model.predict([combine[i]])\n",
    "    dictionary = {\n",
    "        0: \"70mai A400s\",\n",
    "        1: \"70mai A500s\",\n",
    "        2: \"A800s\",\n",
    "        3: \"D08\",\n",
    "        4: \"HuaweiNova3i\",\n",
    "        5: \"Iphone12ProMax\",\n",
    "        6: \"N3Pro\",\n",
    "        7: \"SamsungA23\",\n",
    "        8: \"Z40\"\n",
    "    }\n",
    "    for key, value in dictionary.items():\n",
    "        if key == result[0]:\n",
    "            result = value\n",
    "    \n",
    "    predictions.append(result)\n",
    "    \n",
    "    print(\"Image\", i + 1)\n",
    "    print(\"This image is in class:\", result)\n",
    "    print(\"---\")\n",
    "    \n",
    "most_common_prediction = Counter(predictions).most_common(1)[0][0]\n",
    "print(\"\\nOverall class of the video:\", most_common_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ded1ad1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Submitted: Video3.mp4\n",
      "Total frames in the video submitted: 426\n",
      "Test Images length: 10\n",
      "Image 1\n",
      "This image is in class: HuaweiNova3i\n",
      "---\n",
      "Image 2\n",
      "This image is in class: HuaweiNova3i\n",
      "---\n",
      "Image 3\n",
      "This image is in class: HuaweiNova3i\n",
      "---\n",
      "Image 4\n",
      "This image is in class: HuaweiNova3i\n",
      "---\n",
      "Image 5\n",
      "This image is in class: HuaweiNova3i\n",
      "---\n",
      "Image 6\n",
      "This image is in class: HuaweiNova3i\n",
      "---\n",
      "Image 7\n",
      "This image is in class: HuaweiNova3i\n",
      "---\n",
      "Image 8\n",
      "This image is in class: HuaweiNova3i\n",
      "---\n",
      "Image 9\n",
      "This image is in class: HuaweiNova3i\n",
      "---\n",
      "Image 10\n",
      "This image is in class: HuaweiNova3i\n",
      "---\n",
      "\n",
      "Overall class of the video: HuaweiNova3i\n"
     ]
    }
   ],
   "source": [
    "testImages = []\n",
    "predictions = []\n",
    "\n",
    "video_path = \"C:/Users/hpvic/Python/VideoForgery/UnseenData/Video3.mp4\"\n",
    "vidcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "video_filename = os.path.basename(video_path) \n",
    "print(\"Video Submitted:\", video_filename)  # Display the video path\n",
    "\n",
    "frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"Total frames in the video submitted:\", frameCount) # Display total number of frames\n",
    "frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Select 10 random frame indices\n",
    "randomFrameIndices = random.sample(range(frameCount), 10)\n",
    "\n",
    "for frameIndex in sorted(randomFrameIndices):\n",
    "    # Set the position of the video to the start of the frame\n",
    "    vidcap.set(cv2.CAP_PROP_POS_FRAMES, frameIndex)\n",
    "\n",
    "    # Read the frame\n",
    "    success, image = vidcap.read()\n",
    "    if not success:\n",
    "        print(\"Error reading frame.\")\n",
    "        continue\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.resize(image, (1920, 1080), interpolation=cv2.INTER_LINEAR)\n",
    "    image = cv2.fastNlMeansDenoising(image, None, 10, 7, 21)\n",
    "\n",
    "    # Append the image to the testImages array\n",
    "    testImages.append(image)\n",
    "\n",
    "# Print the lengths of the arrays to verify\n",
    "print(\"Test Images length:\", len(testImages))\n",
    "\n",
    "combine = np.array(testImages)\n",
    "\n",
    "combine = combine.reshape(combine.shape[0], combine.shape[1] * combine.shape[2])\n",
    "\n",
    "for i in range(len(combine)):\n",
    "    result = loaded_model.predict([combine[i]])\n",
    "    dictionary = {\n",
    "        0: \"70mai A400s\",\n",
    "        1: \"70mai A500s\",\n",
    "        2: \"A800s\",\n",
    "        3: \"D08\",\n",
    "        4: \"HuaweiNova3i\",\n",
    "        5: \"Iphone12ProMax\",\n",
    "        6: \"N3Pro\",\n",
    "        7: \"SamsungA23\",\n",
    "        8: \"Z40\"\n",
    "    }\n",
    "    for key, value in dictionary.items():\n",
    "        if key == result[0]:\n",
    "            result = value\n",
    "    \n",
    "    predictions.append(result)\n",
    "    \n",
    "    print(\"Image\", i + 1)\n",
    "    print(\"This image is in class:\", result)\n",
    "    print(\"---\")\n",
    "    \n",
    "most_common_prediction = Counter(predictions).most_common(1)[0][0]\n",
    "print(\"\\nOverall class of the video:\", most_common_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e7b3dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Submitted: UnseenData4.mp4\n",
      "Total frames in the video submitted: 900\n",
      "Test Images length: 10\n",
      "Image 1\n",
      "This image is in class: HuaweiNova3i\n",
      "---\n",
      "Image 2\n",
      "This image is in class: HuaweiNova3i\n",
      "---\n",
      "Image 3\n",
      "This image is in class: SamsungA23\n",
      "---\n",
      "Image 4\n",
      "This image is in class: SamsungA23\n",
      "---\n",
      "Image 5\n",
      "This image is in class: SamsungA23\n",
      "---\n",
      "Image 6\n",
      "This image is in class: SamsungA23\n",
      "---\n",
      "Image 7\n",
      "This image is in class: SamsungA23\n",
      "---\n",
      "Image 8\n",
      "This image is in class: SamsungA23\n",
      "---\n",
      "Image 9\n",
      "This image is in class: SamsungA23\n",
      "---\n",
      "Image 10\n",
      "This image is in class: SamsungA23\n",
      "---\n",
      "\n",
      "Overall class of the video: SamsungA23\n"
     ]
    }
   ],
   "source": [
    "testImages = []\n",
    "predictions = []\n",
    "\n",
    "video_path = \"C:/Users/hpvic/Python/VideoForgery/UnseenData/UnseenData4.mp4\"\n",
    "vidcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "video_filename = os.path.basename(video_path) \n",
    "print(\"Video Submitted:\", video_filename)  # Display the video path\n",
    "\n",
    "frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"Total frames in the video submitted:\", frameCount) # Display total number of frames\n",
    "frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Select 10 random frame indices\n",
    "randomFrameIndices = random.sample(range(frameCount), 10)\n",
    "\n",
    "for frameIndex in sorted(randomFrameIndices):\n",
    "    # Set the position of the video to the start of the frame\n",
    "    vidcap.set(cv2.CAP_PROP_POS_FRAMES, frameIndex)\n",
    "\n",
    "    # Read the frame\n",
    "    success, image = vidcap.read()\n",
    "    if not success:\n",
    "        print(\"Error reading frame.\")\n",
    "        continue\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.resize(image, (1920, 1080), interpolation=cv2.INTER_LINEAR)\n",
    "    image = cv2.fastNlMeansDenoising(image, None, 10, 7, 21)\n",
    "\n",
    "    # Append the image to the testImages array\n",
    "    testImages.append(image)\n",
    "\n",
    "# Print the lengths of the arrays to verify\n",
    "print(\"Test Images length:\", len(testImages))\n",
    "\n",
    "combine = np.array(testImages)\n",
    "\n",
    "combine = combine.reshape(combine.shape[0], combine.shape[1] * combine.shape[2])\n",
    "\n",
    "for i in range(len(combine)):\n",
    "    result = loaded_model.predict([combine[i]])\n",
    "    dictionary = {\n",
    "        0: \"70mai A400s\",\n",
    "        1: \"70mai A500s\",\n",
    "        2: \"A800s\",\n",
    "        3: \"D08\",\n",
    "        4: \"HuaweiNova3i\",\n",
    "        5: \"Iphone12ProMax\",\n",
    "        6: \"N3Pro\",\n",
    "        7: \"SamsungA23\",\n",
    "        8: \"Z40\"\n",
    "    }\n",
    "    for key, value in dictionary.items():\n",
    "        if key == result[0]:\n",
    "            result = value\n",
    "    \n",
    "    predictions.append(result)\n",
    "    \n",
    "    print(\"Image\", i + 1)\n",
    "    print(\"This image is in class:\", result)\n",
    "    print(\"---\")\n",
    "    \n",
    "most_common_prediction = Counter(predictions).most_common(1)[0][0]\n",
    "print(\"\\nOverall class of the video:\", most_common_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268930e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
