{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "121f0eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "\n",
    "filename = 'fogeryDetection3.sav'\n",
    "path = \"C:/Users/hpvic/Python/noise/\"\n",
    "\n",
    "loaded_model = joblib.load(path + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28441738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Submitted: UnseenData2.mp4\n",
      "Total frames in the video submitted: 305\n",
      "Finished reading frames.\n",
      "Overall result: Tampered\n"
     ]
    }
   ],
   "source": [
    "testImages = []\n",
    "tampered_count = 0  # Counter for number of \"Tampered\" images\n",
    "\n",
    "# Open the video file\n",
    "video_path = \"C:/Users/hpvic/Python/VideoForgery/UnseenData/UnseenData2.mp4\"\n",
    "vidcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "video_filename = os.path.basename(video_path) \n",
    "print(\"Video Submitted:\", video_filename)  # Display the video path\n",
    "\n",
    "frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"Total frames in the video submitted:\", frameCount) # Display total number of frames\n",
    "\n",
    "frameIndex = 0\n",
    "\n",
    "while True:\n",
    "    # Set the position of the video to the start of the frame\n",
    "    vidcap.set(cv2.CAP_PROP_POS_FRAMES, frameIndex)\n",
    "\n",
    "    # Read the frame\n",
    "    success, image = vidcap.read()\n",
    "    if not success:\n",
    "        print(\"Finished reading frames.\")\n",
    "        break\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.resize(image, (1920, 1080), interpolation=cv2.INTER_LINEAR)\n",
    "    image = cv2.fastNlMeansDenoising(image, None, 10, 7, 21)\n",
    "\n",
    "    # Append the image to the testImages array\n",
    "    testImages.append(image)\n",
    "    frameIndex += 1\n",
    "\n",
    "combine = np.array(testImages)\n",
    "combine = combine.reshape(combine.shape[0], combine.shape[1] * combine.shape[2])\n",
    "\n",
    "for i in range(len(combine)):\n",
    "    result = loaded_model.predict([combine[i]])[0]  # Directly access the first (and only) item in the list\n",
    "    if result.lower() == \"tampered\":\n",
    "        tampered_count += 1\n",
    "    \n",
    "# If more than or equal to 20% of the images are \"Tampered\", classify the overall result as \"Tampered\"\n",
    "if tampered_count / len(testImages) >= 0.2:\n",
    "    print(\"Overall result: Tampered\")\n",
    "else:\n",
    "    print(\"Overall result: Original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b936106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Submitted: Video3.mp4\n",
      "Total frames in the video submitted: 426\n",
      "Finished reading frames.\n",
      "Overall result: Original\n"
     ]
    }
   ],
   "source": [
    "testImages = []\n",
    "tampered_count = 0  # Counter for number of \"Tampered\" images\n",
    "\n",
    "# Open the video file\n",
    "video_path = \"C:/Users/hpvic/Python/VideoForgery/UnseenData/Video3.mp4\"\n",
    "vidcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "video_filename = os.path.basename(video_path) \n",
    "print(\"Video Submitted:\", video_filename)  # Display the video path\n",
    "\n",
    "frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"Total frames in the video submitted:\", frameCount) # Display total number of frames\n",
    "\n",
    "frameIndex = 0\n",
    "\n",
    "while True:\n",
    "    # Set the position of the video to the start of the frame\n",
    "    vidcap.set(cv2.CAP_PROP_POS_FRAMES, frameIndex)\n",
    "\n",
    "    # Read the frame\n",
    "    success, image = vidcap.read()\n",
    "    if not success:\n",
    "        print(\"Finished reading frames.\")\n",
    "        break\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.resize(image, (1920, 1080), interpolation=cv2.INTER_LINEAR)\n",
    "    image = cv2.fastNlMeansDenoising(image, None, 10, 7, 21)\n",
    "\n",
    "    # Append the image to the testImages array\n",
    "    testImages.append(image)\n",
    "    frameIndex += 1\n",
    "\n",
    "combine = np.array(testImages)\n",
    "combine = combine.reshape(combine.shape[0], combine.shape[1] * combine.shape[2])\n",
    "\n",
    "for i in range(len(combine)):\n",
    "    result = loaded_model.predict([combine[i]])[0]  # Directly access the first (and only) item in the list\n",
    "    if result.lower() == \"tampered\":\n",
    "        tampered_count += 1\n",
    "    \n",
    "# If more than or equal to 20% of the images are \"Tampered\", classify the overall result as \"Tampered\"\n",
    "if tampered_count / len(testImages) >= 0.2:\n",
    "    print(\"Overall result: Tampered\")\n",
    "else:\n",
    "    print(\"Overall result: Original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b38851d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Submitted: UnseenData1.mp4\n",
      "Total frames in the video submitted: 1213\n",
      "Finished reading frames.\n",
      "Overall result: Tampered\n"
     ]
    }
   ],
   "source": [
    "testImages = []\n",
    "tampered_count = 0  # Counter for number of \"Tampered\" images\n",
    "\n",
    "# Open the video file\n",
    "video_path = \"C:/Users/hpvic/Python/VideoForgery/UnseenData/UnseenData1.mp4\"\n",
    "vidcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "video_filename = os.path.basename(video_path) \n",
    "print(\"Video Submitted:\", video_filename)  # Display the video path\n",
    "\n",
    "frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"Total frames in the video submitted:\", frameCount) # Display total number of frames\n",
    "\n",
    "frameIndex = 0\n",
    "\n",
    "while True:\n",
    "    # Set the position of the video to the start of the frame\n",
    "    vidcap.set(cv2.CAP_PROP_POS_FRAMES, frameIndex)\n",
    "\n",
    "    # Read the frame\n",
    "    success, image = vidcap.read()\n",
    "    if not success:\n",
    "        print(\"Finished reading frames.\")\n",
    "        break\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.resize(image, (1920, 1080), interpolation=cv2.INTER_LINEAR)\n",
    "    image = cv2.fastNlMeansDenoising(image, None, 10, 7, 21)\n",
    "\n",
    "    # Append the image to the testImages array\n",
    "    testImages.append(image)\n",
    "    frameIndex += 1\n",
    "\n",
    "combine = np.array(testImages)\n",
    "combine = combine.reshape(combine.shape[0], combine.shape[1] * combine.shape[2])\n",
    "\n",
    "for i in range(len(combine)):\n",
    "    result = loaded_model.predict([combine[i]])[0]  # Directly access the first (and only) item in the list\n",
    "    if result.lower() == \"tampered\":\n",
    "        tampered_count += 1\n",
    "    \n",
    "# If more than or equal to 20% of the images are \"Tampered\", classify the overall result as \"Tampered\"\n",
    "if tampered_count / len(testImages) >= 0.2:\n",
    "    print(\"Overall result: Tampered\")\n",
    "else:\n",
    "    print(\"Overall result: Original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "072e0237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Submitted: UnseenData3.mp4\n",
      "Total frames in the video submitted: 1839\n",
      "Finished reading frames.\n",
      "Overall result: Tampered\n"
     ]
    }
   ],
   "source": [
    "testImages = []\n",
    "tampered_count = 0  # Counter for number of \"Tampered\" images\n",
    "\n",
    "# Open the video file\n",
    "video_path = \"C:/Users/hpvic/Python/VideoForgery/UnseenData/UnseenData3.mp4\"\n",
    "vidcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "video_filename = os.path.basename(video_path) \n",
    "print(\"Video Submitted:\", video_filename)  # Display the video path\n",
    "\n",
    "frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"Total frames in the video submitted:\", frameCount) # Display total number of frames\n",
    "\n",
    "frameIndex = 0\n",
    "\n",
    "while True:\n",
    "    # Set the position of the video to the start of the frame\n",
    "    vidcap.set(cv2.CAP_PROP_POS_FRAMES, frameIndex)\n",
    "\n",
    "    # Read the frame\n",
    "    success, image = vidcap.read()\n",
    "    if not success:\n",
    "        print(\"Finished reading frames.\")\n",
    "        break\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.resize(image, (1920, 1080), interpolation=cv2.INTER_LINEAR)\n",
    "    image = cv2.fastNlMeansDenoising(image, None, 10, 7, 21)\n",
    "\n",
    "    # Append the image to the testImages array\n",
    "    testImages.append(image)\n",
    "    frameIndex += 1\n",
    "\n",
    "combine = np.array(testImages)\n",
    "combine = combine.reshape(combine.shape[0], combine.shape[1] * combine.shape[2])\n",
    "\n",
    "for i in range(len(combine)):\n",
    "    result = loaded_model.predict([combine[i]])[0]  # Directly access the first (and only) item in the list\n",
    "    if result.lower() == \"tampered\":\n",
    "        tampered_count += 1\n",
    "    \n",
    "# If more than or equal to 20% of the images are \"Tampered\", classify the overall result as \"Tampered\"\n",
    "if tampered_count / len(testImages) >= 0.2:\n",
    "    print(\"Overall result: Tampered\")\n",
    "else:\n",
    "    print(\"Overall result: Original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "999fb481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Submitted: UnseenData4.mp4\n",
      "Total frames in the video submitted: 900\n",
      "Finished reading frames.\n",
      "Overall result: Tampered\n"
     ]
    }
   ],
   "source": [
    "testImages = []\n",
    "tampered_count = 0  # Counter for number of \"Tampered\" images\n",
    "\n",
    "# Open the video file\n",
    "video_path = \"C:/Users/hpvic/Python/VideoForgery/UnseenData/UnseenData4.mp4\"\n",
    "vidcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "video_filename = os.path.basename(video_path) \n",
    "print(\"Video Submitted:\", video_filename)  # Display the video path\n",
    "\n",
    "frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"Total frames in the video submitted:\", frameCount) # Display total number of frames\n",
    "\n",
    "frameIndex = 0\n",
    "\n",
    "while True:\n",
    "    # Set the position of the video to the start of the frame\n",
    "    vidcap.set(cv2.CAP_PROP_POS_FRAMES, frameIndex)\n",
    "\n",
    "    # Read the frame\n",
    "    success, image = vidcap.read()\n",
    "    if not success:\n",
    "        print(\"Finished reading frames.\")\n",
    "        break\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.resize(image, (1920, 1080), interpolation=cv2.INTER_LINEAR)\n",
    "    image = cv2.fastNlMeansDenoising(image, None, 10, 7, 21)\n",
    "\n",
    "    # Append the image to the testImages array\n",
    "    testImages.append(image)\n",
    "    frameIndex += 1\n",
    "\n",
    "combine = np.array(testImages)\n",
    "combine = combine.reshape(combine.shape[0], combine.shape[1] * combine.shape[2])\n",
    "\n",
    "for i in range(len(combine)):\n",
    "    result = loaded_model.predict([combine[i]])[0]  # Directly access the first (and only) item in the list\n",
    "    if result.lower() == \"tampered\":\n",
    "        tampered_count += 1\n",
    "    \n",
    "# If more than or equal to 20% of the images are \"Tampered\", classify the overall result as \"Tampered\"\n",
    "if tampered_count / len(testImages) >= 0.2:\n",
    "    print(\"Overall result: Tampered\")\n",
    "else:\n",
    "    print(\"Overall result: Original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c3dea74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Submitted: UnseenData5.mp4\n",
      "Total frames in the video submitted: 1106\n",
      "Finished reading frames.\n",
      "Overall result: Original\n"
     ]
    }
   ],
   "source": [
    "testImages = []\n",
    "tampered_count = 0  # Counter for number of \"Tampered\" images\n",
    "\n",
    "# Open the video file\n",
    "video_path = \"C:/Users/hpvic/Python/VideoForgery/UnseenData/UnseenData5.mp4\"\n",
    "vidcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "video_filename = os.path.basename(video_path) \n",
    "print(\"Video Submitted:\", video_filename)  # Display the video path\n",
    "\n",
    "frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"Total frames in the video submitted:\", frameCount) # Display total number of frames\n",
    "\n",
    "frameIndex = 0\n",
    "\n",
    "while True:\n",
    "    # Set the position of the video to the start of the frame\n",
    "    vidcap.set(cv2.CAP_PROP_POS_FRAMES, frameIndex)\n",
    "\n",
    "    # Read the frame\n",
    "    success, image = vidcap.read()\n",
    "    if not success:\n",
    "        print(\"Finished reading frames.\")\n",
    "        break\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.resize(image, (1920, 1080), interpolation=cv2.INTER_LINEAR)\n",
    "    image = cv2.fastNlMeansDenoising(image, None, 10, 7, 21)\n",
    "\n",
    "    # Append the image to the testImages array\n",
    "    testImages.append(image)\n",
    "    frameIndex += 1\n",
    "\n",
    "combine = np.array(testImages)\n",
    "combine = combine.reshape(combine.shape[0], combine.shape[1] * combine.shape[2])\n",
    "\n",
    "for i in range(len(combine)):\n",
    "    result = loaded_model.predict([combine[i]])[0]  # Directly access the first (and only) item in the list\n",
    "    if result.lower() == \"tampered\":\n",
    "        tampered_count += 1\n",
    "    \n",
    "# If more than or equal to 20% of the images are \"Tampered\", classify the overall result as \"Tampered\"\n",
    "if tampered_count / len(testImages) >= 0.2:\n",
    "    print(\"Overall result: Tampered\")\n",
    "else:\n",
    "    print(\"Overall result: Original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3d714ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Submitted: UnseenData6.mp4\n",
      "Total frames in the video submitted: 1860\n",
      "Finished reading frames.\n",
      "Overall result: Original\n"
     ]
    }
   ],
   "source": [
    "testImages = []\n",
    "tampered_count = 0  # Counter for number of \"Tampered\" images\n",
    "\n",
    "# Open the video file\n",
    "video_path = \"C:/Users/hpvic/Python/VideoForgery/UnseenData/UnseenData6.mp4\"\n",
    "vidcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "video_filename = os.path.basename(video_path) \n",
    "print(\"Video Submitted:\", video_filename)  # Display the video path\n",
    "\n",
    "frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"Total frames in the video submitted:\", frameCount) # Display total number of frames\n",
    "\n",
    "frameIndex = 0\n",
    "\n",
    "while True:\n",
    "    # Set the position of the video to the start of the frame\n",
    "    vidcap.set(cv2.CAP_PROP_POS_FRAMES, frameIndex)\n",
    "\n",
    "    # Read the frame\n",
    "    success, image = vidcap.read()\n",
    "    if not success:\n",
    "        print(\"Finished reading frames.\")\n",
    "        break\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.resize(image, (1920, 1080), interpolation=cv2.INTER_LINEAR)\n",
    "    image = cv2.fastNlMeansDenoising(image, None, 10, 7, 21)\n",
    "\n",
    "    # Append the image to the testImages array\n",
    "    testImages.append(image)\n",
    "    frameIndex += 1\n",
    "\n",
    "combine = np.array(testImages)\n",
    "combine = combine.reshape(combine.shape[0], combine.shape[1] * combine.shape[2])\n",
    "\n",
    "for i in range(len(combine)):\n",
    "    result = loaded_model.predict([combine[i]])[0]  # Directly access the first (and only) item in the list\n",
    "    if result.lower() == \"tampered\":\n",
    "        tampered_count += 1\n",
    "    \n",
    "# If more than or equal to 20% of the images are \"Tampered\", classify the overall result as \"Tampered\"\n",
    "if tampered_count / len(testImages) >= 0.2:\n",
    "    print(\"Overall result: Tampered\")\n",
    "else:\n",
    "    print(\"Overall result: Original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fd4f04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Submitted: unknown.mp4\n",
      "Total frames in the video submitted: 825\n",
      "Finished reading frames.\n",
      "Overall result: Original\n"
     ]
    }
   ],
   "source": [
    "testImages = []\n",
    "tampered_count = 0  # Counter for number of \"Tampered\" images\n",
    "\n",
    "# Open the video file\n",
    "video_path = \"C:/Users/hpvic/Python/VideoForgery/UnseenData/unknown.mp4\"\n",
    "vidcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "video_filename = os.path.basename(video_path) \n",
    "print(\"Video Submitted:\", video_filename)  # Display the video path\n",
    "\n",
    "frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"Total frames in the video submitted:\", frameCount) # Display total number of frames\n",
    "\n",
    "frameIndex = 0\n",
    "\n",
    "while True:\n",
    "    # Set the position of the video to the start of the frame\n",
    "    vidcap.set(cv2.CAP_PROP_POS_FRAMES, frameIndex)\n",
    "\n",
    "    # Read the frame\n",
    "    success, image = vidcap.read()\n",
    "    if not success:\n",
    "        print(\"Finished reading frames.\")\n",
    "        break\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.resize(image, (1920, 1080), interpolation=cv2.INTER_LINEAR)\n",
    "    image = cv2.fastNlMeansDenoising(image, None, 10, 7, 21)\n",
    "\n",
    "    # Append the image to the testImages array\n",
    "    testImages.append(image)\n",
    "    frameIndex += 1\n",
    "\n",
    "combine = np.array(testImages)\n",
    "combine = combine.reshape(combine.shape[0], combine.shape[1] * combine.shape[2])\n",
    "\n",
    "for i in range(len(combine)):\n",
    "    result = loaded_model.predict([combine[i]])[0]  # Directly access the first (and only) item in the list\n",
    "    if result.lower() == \"tampered\":\n",
    "        tampered_count += 1\n",
    "    \n",
    "# If more than or equal to 20% of the images are \"Tampered\", classify the overall result as \"Tampered\"\n",
    "if tampered_count / len(testImages) >= 0.2:\n",
    "    print(\"Overall result: Tampered\")\n",
    "else:\n",
    "    print(\"Overall result: Original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363e4248",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
