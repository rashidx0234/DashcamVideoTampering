{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4ca633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "filename = 'model5.sav'\n",
    "path = \"C:/Users/hpvic/Python/noise/\"\n",
    "\n",
    "loaded_model = joblib.load(path + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36561a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename2 = 'fogeryDetection3.sav'\n",
    "path2 = \"C:/Users/hpvic/Python/noise/\"\n",
    "\n",
    "loaded_model2 = joblib.load(path2 + filename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4817908",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dictionary = {\n",
    "    0: \"70mai A400s\",\n",
    "    1: \"70mai A500s\",\n",
    "    2: \"A800s\",\n",
    "    3: \"D08\",\n",
    "    4: \"HuaweiNova3i\",\n",
    "    5: \"Iphone12ProMax\",\n",
    "    6: \"N3Pro\",\n",
    "    7: \"SamsungA23\",\n",
    "    8: \"Z40\"\n",
    "}\n",
    "\n",
    "def process_video(video_path, model1, model2):\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    video_filename = os.path.basename(video_path) \n",
    "    print(\"Video Submitted:\", video_filename)  # Display the video path\n",
    "\n",
    "    frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(\"Total frames in the video submitted:\", frameCount) # Display total number of frames\n",
    "\n",
    "    predictions = []\n",
    "    tampered_count = 0\n",
    "\n",
    "    for frameIndex in range(frameCount):\n",
    "        # Set the position of the video to the start of the frame\n",
    "        vidcap.set(cv2.CAP_PROP_POS_FRAMES, frameIndex)\n",
    "\n",
    "        # Read the frame\n",
    "        success, image = vidcap.read()\n",
    "        if not success:\n",
    "            print(\"Error reading frame.\")\n",
    "            continue\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.resize(image, (1920, 1080), interpolation=cv2.INTER_LINEAR)\n",
    "        image = cv2.fastNlMeansDenoising(image, None, 10, 7, 21)\n",
    "\n",
    "        image_reshaped = image.reshape(-1, image.shape[0] * image.shape[1])\n",
    "\n",
    "        # Use model 1 to classify device source\n",
    "        device_source_pred = model1.predict(image_reshaped)[0]\n",
    "        predictions.append(label_dictionary[device_source_pred])\n",
    "\n",
    "        # Use model 2 to classify whether the video is tampered or not\n",
    "        tamper_status_pred = model2.predict(image_reshaped)[0]\n",
    "        if tamper_status_pred.lower() == \"tampered\":\n",
    "            tampered_count += 1\n",
    "\n",
    "    most_common_prediction = Counter(predictions).most_common(1)[0][0]\n",
    "    print(\"\\nOverall class of the video:\", most_common_prediction)\n",
    "\n",
    "    if tampered_count / frameCount >= 0.2:\n",
    "        print(\"Overall result: Tampered\")\n",
    "    else:\n",
    "        print(\"Overall result: Original\")\n",
    "\n",
    "# Path to your video\n",
    "video_path = \"C:/Users/hpvic/Python/VideoForgery/UnseenData/70maiA400.mp4\"\n",
    "process_video(video_path, loaded_model, loaded_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1ec457f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Submitted: UnseenData2.mp4\n",
      "Total frames in the video submitted: 305\n",
      "\n",
      "Overall class of the video: Iphone12ProMax\n",
      "Overall result: Tampered\n"
     ]
    }
   ],
   "source": [
    "label_dictionary = {\n",
    "    0: \"70mai A400s\",\n",
    "    1: \"70mai A500s\",\n",
    "    2: \"A800s\",\n",
    "    3: \"D08\",\n",
    "    4: \"HuaweiNova3i\",\n",
    "    5: \"Iphone12ProMax\",\n",
    "    6: \"N3Pro\",\n",
    "    7: \"SamsungA23\",\n",
    "    8: \"Z40\"\n",
    "}\n",
    "\n",
    "def process_video(video_path, model1, model2):\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    video_filename = os.path.basename(video_path) \n",
    "    print(\"Video Submitted:\", video_filename)  # Display the video path\n",
    "\n",
    "    frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(\"Total frames in the video submitted:\", frameCount) # Display total number of frames\n",
    "\n",
    "    predictions = []\n",
    "    tampered_count = 0\n",
    "\n",
    "    for frameIndex in range(frameCount):\n",
    "        # Set the position of the video to the start of the frame\n",
    "        vidcap.set(cv2.CAP_PROP_POS_FRAMES, frameIndex)\n",
    "\n",
    "        # Read the frame\n",
    "        success, image = vidcap.read()\n",
    "        if not success:\n",
    "            print(\"Error reading frame.\")\n",
    "            continue\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.resize(image, (1920, 1080), interpolation=cv2.INTER_LINEAR)\n",
    "        image = cv2.fastNlMeansDenoising(image, None, 10, 7, 21)\n",
    "\n",
    "        image_reshaped = image.reshape(-1, image.shape[0] * image.shape[1])\n",
    "\n",
    "        # Use model 1 to classify device source\n",
    "        device_source_pred = model1.predict(image_reshaped)[0]\n",
    "        predictions.append(label_dictionary[device_source_pred])\n",
    "\n",
    "        # Use model 2 to classify whether the video is tampered or not\n",
    "        tamper_status_pred = model2.predict(image_reshaped)[0]\n",
    "        if tamper_status_pred.lower() == \"tampered\":\n",
    "            tampered_count += 1\n",
    "\n",
    "    most_common_prediction = Counter(predictions).most_common(1)[0][0]\n",
    "    print(\"\\nOverall class of the video:\", most_common_prediction)\n",
    "\n",
    "    if tampered_count / frameCount >= 0.2:\n",
    "        print(\"Overall result: Tampered\")\n",
    "    else:\n",
    "        print(\"Overall result: Original\")\n",
    "\n",
    "# Path to your video\n",
    "video_path = \"C:/Users/hpvic/Python/VideoForgery/UnseenData/UnseenData2.mp4\"\n",
    "process_video(video_path, loaded_model, loaded_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84aedc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Submitted: SamsungA23.mp4\n",
      "Total frames in the video submitted: 350\n",
      "\n",
      "Overall class of the video: SamsungA23\n",
      "Overall result: Original\n"
     ]
    }
   ],
   "source": [
    "label_dictionary = {\n",
    "    0: \"70mai A400s\",\n",
    "    1: \"70mai A500s\",\n",
    "    2: \"A800s\",\n",
    "    3: \"D08\",\n",
    "    4: \"HuaweiNova3i\",\n",
    "    5: \"Iphone12ProMax\",\n",
    "    6: \"N3Pro\",\n",
    "    7: \"SamsungA23\",\n",
    "    8: \"Z40\"\n",
    "}\n",
    "\n",
    "def process_video(video_path, model1, model2):\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    video_filename = os.path.basename(video_path) \n",
    "    print(\"Video Submitted:\", video_filename)  # Display the video path\n",
    "\n",
    "    frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(\"Total frames in the video submitted:\", frameCount) # Display total number of frames\n",
    "\n",
    "    predictions = []\n",
    "    tampered_count = 0\n",
    "\n",
    "    for frameIndex in range(frameCount):\n",
    "        # Set the position of the video to the start of the frame\n",
    "        vidcap.set(cv2.CAP_PROP_POS_FRAMES, frameIndex)\n",
    "\n",
    "        # Read the frame\n",
    "        success, image = vidcap.read()\n",
    "        if not success:\n",
    "            print(\"Error reading frame.\")\n",
    "            continue\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.resize(image, (1920, 1080), interpolation=cv2.INTER_LINEAR)\n",
    "        image = cv2.fastNlMeansDenoising(image, None, 10, 7, 21)\n",
    "\n",
    "        image_reshaped = image.reshape(-1, image.shape[0] * image.shape[1])\n",
    "\n",
    "        # Use model 1 to classify device source\n",
    "        device_source_pred = model1.predict(image_reshaped)[0]\n",
    "        predictions.append(label_dictionary[device_source_pred])\n",
    "\n",
    "        # Use model 2 to classify whether the video is tampered or not\n",
    "        tamper_status_pred = model2.predict(image_reshaped)[0]\n",
    "        if tamper_status_pred.lower() == \"tampered\":\n",
    "            tampered_count += 1\n",
    "\n",
    "    most_common_prediction = Counter(predictions).most_common(1)[0][0]\n",
    "    print(\"\\nOverall class of the video:\", most_common_prediction)\n",
    "\n",
    "    if tampered_count / frameCount >= 0.2:\n",
    "        print(\"Overall result: Tampered\")\n",
    "    else:\n",
    "        print(\"Overall result: Original\")\n",
    "\n",
    "# Path to your video\n",
    "video_path = \"C:/Users/hpvic/Python/VideoForgery/UnseenData/SamsungA23.mp4\"\n",
    "process_video(video_path, loaded_model, loaded_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be9a87cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Submitted: unknown.mp4\n",
      "Total frames in the video submitted: 825\n",
      "\n",
      "Overall class of the video: SamsungA23\n",
      "Overall result: Original\n"
     ]
    }
   ],
   "source": [
    "label_dictionary = {\n",
    "    0: \"70mai A400s\",\n",
    "    1: \"70mai A500s\",\n",
    "    2: \"A800s\",\n",
    "    3: \"D08\",\n",
    "    4: \"HuaweiNova3i\",\n",
    "    5: \"Iphone12ProMax\",\n",
    "    6: \"N3Pro\",\n",
    "    7: \"SamsungA23\",\n",
    "    8: \"Z40\"\n",
    "}\n",
    "\n",
    "def process_video(video_path, model1, model2):\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    video_filename = os.path.basename(video_path) \n",
    "    print(\"Video Submitted:\", video_filename)  # Display the video path\n",
    "\n",
    "    frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(\"Total frames in the video submitted:\", frameCount) # Display total number of frames\n",
    "\n",
    "    predictions = []\n",
    "    tampered_count = 0\n",
    "\n",
    "    for frameIndex in range(frameCount):\n",
    "        # Set the position of the video to the start of the frame\n",
    "        vidcap.set(cv2.CAP_PROP_POS_FRAMES, frameIndex)\n",
    "\n",
    "        # Read the frame\n",
    "        success, image = vidcap.read()\n",
    "        if not success:\n",
    "            print(\"Error reading frame.\")\n",
    "            continue\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.resize(image, (1920, 1080), interpolation=cv2.INTER_LINEAR)\n",
    "        image = cv2.fastNlMeansDenoising(image, None, 10, 7, 21)\n",
    "\n",
    "        image_reshaped = image.reshape(-1, image.shape[0] * image.shape[1])\n",
    "\n",
    "        # Use model 1 to classify device source\n",
    "        device_source_pred = model1.predict(image_reshaped)[0]\n",
    "        predictions.append(label_dictionary[device_source_pred])\n",
    "\n",
    "        # Use model 2 to classify whether the video is tampered or not\n",
    "        tamper_status_pred = model2.predict(image_reshaped)[0]\n",
    "        if tamper_status_pred.lower() == \"tampered\":\n",
    "            tampered_count += 1\n",
    "\n",
    "    most_common_prediction = Counter(predictions).most_common(1)[0][0]\n",
    "    print(\"\\nOverall class of the video:\", most_common_prediction)\n",
    "\n",
    "    if tampered_count / frameCount >= 0.2:\n",
    "        print(\"Overall result: Tampered\")\n",
    "    else:\n",
    "        print(\"Overall result: Original\")\n",
    "\n",
    "# Path to your video\n",
    "video_path = \"C:/Users/hpvic/Python/VideoForgery/UnseenData/unknown.mp4\"\n",
    "process_video(video_path, loaded_model, loaded_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f83a7953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Submitted: video3.mp4\n",
      "Total frames in the video submitted: 426\n",
      "\n",
      "Overall class of the video: HuaweiNova3i\n",
      "Overall result: Original\n"
     ]
    }
   ],
   "source": [
    "label_dictionary = {\n",
    "    0: \"70mai A400s\",\n",
    "    1: \"70mai A500s\",\n",
    "    2: \"A800s\",\n",
    "    3: \"D08\",\n",
    "    4: \"HuaweiNova3i\",\n",
    "    5: \"Iphone12ProMax\",\n",
    "    6: \"N3Pro\",\n",
    "    7: \"SamsungA23\",\n",
    "    8: \"Z40\"\n",
    "}\n",
    "\n",
    "def process_video(video_path, model1, model2):\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    video_filename = os.path.basename(video_path) \n",
    "    print(\"Video Submitted:\", video_filename)  # Display the video path\n",
    "\n",
    "    frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(\"Total frames in the video submitted:\", frameCount) # Display total number of frames\n",
    "\n",
    "    predictions = []\n",
    "    tampered_count = 0\n",
    "\n",
    "    for frameIndex in range(frameCount):\n",
    "        # Set the position of the video to the start of the frame\n",
    "        vidcap.set(cv2.CAP_PROP_POS_FRAMES, frameIndex)\n",
    "\n",
    "        # Read the frame\n",
    "        success, image = vidcap.read()\n",
    "        if not success:\n",
    "            print(\"Error reading frame.\")\n",
    "            continue\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.resize(image, (1920, 1080), interpolation=cv2.INTER_LINEAR)\n",
    "        image = cv2.fastNlMeansDenoising(image, None, 10, 7, 21)\n",
    "\n",
    "        image_reshaped = image.reshape(-1, image.shape[0] * image.shape[1])\n",
    "\n",
    "        # Use model 1 to classify device source\n",
    "        device_source_pred = model1.predict(image_reshaped)[0]\n",
    "        predictions.append(label_dictionary[device_source_pred])\n",
    "\n",
    "        # Use model 2 to classify whether the video is tampered or not\n",
    "        tamper_status_pred = model2.predict(image_reshaped)[0]\n",
    "        if tamper_status_pred.lower() == \"tampered\":\n",
    "            tampered_count += 1\n",
    "\n",
    "    most_common_prediction = Counter(predictions).most_common(1)[0][0]\n",
    "    print(\"\\nOverall class of the video:\", most_common_prediction)\n",
    "\n",
    "    if tampered_count / frameCount >= 0.2:\n",
    "        print(\"Overall result: Tampered\")\n",
    "    else:\n",
    "        print(\"Overall result: Original\")\n",
    "\n",
    "# Path to your video\n",
    "video_path = \"C:/Users/hpvic/Python/VideoForgery/UnseenData/video3.mp4\"\n",
    "process_video(video_path, loaded_model, loaded_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "104a0918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Submitted: UnseenData1.mp4\n",
      "Total frames in the video submitted: 1213\n",
      "\n",
      "Overall class of the video: Iphone12ProMax\n",
      "Overall result: Tampered\n"
     ]
    }
   ],
   "source": [
    "label_dictionary = {\n",
    "    0: \"70mai A400s\",\n",
    "    1: \"70mai A500s\",\n",
    "    2: \"A800s\",\n",
    "    3: \"D08\",\n",
    "    4: \"HuaweiNova3i\",\n",
    "    5: \"Iphone12ProMax\",\n",
    "    6: \"N3Pro\",\n",
    "    7: \"SamsungA23\",\n",
    "    8: \"Z40\"\n",
    "}\n",
    "\n",
    "def process_video(video_path, model1, model2):\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    video_filename = os.path.basename(video_path) \n",
    "    print(\"Video Submitted:\", video_filename)  # Display the video path\n",
    "\n",
    "    frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(\"Total frames in the video submitted:\", frameCount) # Display total number of frames\n",
    "\n",
    "    predictions = []\n",
    "    tampered_count = 0\n",
    "\n",
    "    for frameIndex in range(frameCount):\n",
    "        # Set the position of the video to the start of the frame\n",
    "        vidcap.set(cv2.CAP_PROP_POS_FRAMES, frameIndex)\n",
    "\n",
    "        # Read the frame\n",
    "        success, image = vidcap.read()\n",
    "        if not success:\n",
    "            print(\"Error reading frame.\")\n",
    "            continue\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.resize(image, (1920, 1080), interpolation=cv2.INTER_LINEAR)\n",
    "        image = cv2.fastNlMeansDenoising(image, None, 10, 7, 21)\n",
    "\n",
    "        image_reshaped = image.reshape(-1, image.shape[0] * image.shape[1])\n",
    "\n",
    "        # Use model 1 to classify device source\n",
    "        device_source_pred = model1.predict(image_reshaped)[0]\n",
    "        predictions.append(label_dictionary[device_source_pred])\n",
    "\n",
    "        # Use model 2 to classify whether the video is tampered or not\n",
    "        tamper_status_pred = model2.predict(image_reshaped)[0]\n",
    "        if tamper_status_pred.lower() == \"tampered\":\n",
    "            tampered_count += 1\n",
    "\n",
    "    most_common_prediction = Counter(predictions).most_common(1)[0][0]\n",
    "    print(\"\\nOverall class of the video:\", most_common_prediction)\n",
    "\n",
    "    if tampered_count / frameCount >= 0.2:\n",
    "        print(\"Overall result: Tampered\")\n",
    "    else:\n",
    "        print(\"Overall result: Original\")\n",
    "\n",
    "# Path to your video\n",
    "video_path = \"C:/Users/hpvic/Python/VideoForgery/UnseenData/UnseenData1.mp4\"\n",
    "process_video(video_path, loaded_model, loaded_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b10efb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Submitted: UnseenData4.mp4\n",
      "Total frames in the video submitted: 900\n",
      "\n",
      "Overall class of the video: HuaweiNova3i\n",
      "Overall result: Tampered\n"
     ]
    }
   ],
   "source": [
    "label_dictionary = {\n",
    "    0: \"70mai A400s\",\n",
    "    1: \"70mai A500s\",\n",
    "    2: \"A800s\",\n",
    "    3: \"D08\",\n",
    "    4: \"HuaweiNova3i\",\n",
    "    5: \"Iphone12ProMax\",\n",
    "    6: \"N3Pro\",\n",
    "    7: \"SamsungA23\",\n",
    "    8: \"Z40\"\n",
    "}\n",
    "\n",
    "def process_video(video_path, model1, model2):\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    video_filename = os.path.basename(video_path) \n",
    "    print(\"Video Submitted:\", video_filename)  # Display the video path\n",
    "\n",
    "    frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(\"Total frames in the video submitted:\", frameCount) # Display total number of frames\n",
    "\n",
    "    predictions = []\n",
    "    tampered_count = 0\n",
    "\n",
    "    for frameIndex in range(frameCount):\n",
    "        # Set the position of the video to the start of the frame\n",
    "        vidcap.set(cv2.CAP_PROP_POS_FRAMES, frameIndex)\n",
    "\n",
    "        # Read the frame\n",
    "        success, image = vidcap.read()\n",
    "        if not success:\n",
    "            print(\"Error reading frame.\")\n",
    "            continue\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.resize(image, (1920, 1080), interpolation=cv2.INTER_LINEAR)\n",
    "        image = cv2.fastNlMeansDenoising(image, None, 10, 7, 21)\n",
    "\n",
    "        image_reshaped = image.reshape(-1, image.shape[0] * image.shape[1])\n",
    "\n",
    "        # Use model 1 to classify device source\n",
    "        device_source_pred = model1.predict(image_reshaped)[0]\n",
    "        predictions.append(label_dictionary[device_source_pred])\n",
    "\n",
    "        # Use model 2 to classify whether the video is tampered or not\n",
    "        tamper_status_pred = model2.predict(image_reshaped)[0]\n",
    "        if tamper_status_pred.lower() == \"tampered\":\n",
    "            tampered_count += 1\n",
    "\n",
    "    most_common_prediction = Counter(predictions).most_common(1)[0][0]\n",
    "    print(\"\\nOverall class of the video:\", most_common_prediction)\n",
    "\n",
    "    if tampered_count / frameCount >= 0.2:\n",
    "        print(\"Overall result: Tampered\")\n",
    "    else:\n",
    "        print(\"Overall result: Original\")\n",
    "\n",
    "# Path to your video\n",
    "video_path = \"C:/Users/hpvic/Python/VideoForgery/UnseenData/UnseenData4.mp4\"\n",
    "process_video(video_path, loaded_model, loaded_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38975ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
