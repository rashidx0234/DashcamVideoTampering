{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8a53efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "filename = 'model5.sav'\n",
    "path = \"C:/Users/hpvic/Python/noise/\"\n",
    "\n",
    "loaded_model = joblib.load(path + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc30857a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Submitted: SamsungA23.mp4\n",
      "Total frames in the video submitted: 350\n",
      "\n",
      "Overall class of the video: SamsungA23\n"
     ]
    }
   ],
   "source": [
    "testImages = []\n",
    "predictions = []\n",
    "\n",
    "video_path = \"C:/Users/hpvic/Python/VideoForgery/UnseenData/SamsungA23.mp4\"\n",
    "vidcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "video_filename = os.path.basename(video_path) \n",
    "print(\"Video Submitted:\", video_filename)  # Display the video path\n",
    "\n",
    "frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"Total frames in the video submitted:\", frameCount) # Display total number of frames\n",
    "\n",
    "for frameIndex in range(frameCount):\n",
    "    # Set the position of the video to the start of the frame\n",
    "    vidcap.set(cv2.CAP_PROP_POS_FRAMES, frameIndex)\n",
    "\n",
    "    # Read the frame\n",
    "    success, image = vidcap.read()\n",
    "    if not success:\n",
    "        print(\"Error reading frame.\")\n",
    "        continue\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.resize(image, (1920, 1080), interpolation=cv2.INTER_LINEAR)\n",
    "    image = cv2.fastNlMeansDenoising(image, None, 10, 7, 21)\n",
    "\n",
    "    # Append the image to the testImages array\n",
    "    testImages.append(image)\n",
    "\n",
    "# Reshape the images for prediction\n",
    "combine = np.array(testImages)\n",
    "combine = combine.reshape(combine.shape[0], combine.shape[1] * combine.shape[2])\n",
    "\n",
    "# Classify each image and append its class to the predictions array\n",
    "for i in range(len(combine)):\n",
    "    result = loaded_model.predict([combine[i]])\n",
    "    dictionary = {\n",
    "        0: \"70mai A400s\",\n",
    "        1: \"70mai A500s\",\n",
    "        2: \"A800s\",\n",
    "        3: \"D08\",\n",
    "        4: \"HuaweiNova3i\",\n",
    "        5: \"Iphone12ProMax\",\n",
    "        6: \"N3Pro\",\n",
    "        7: \"SamsungA23\",\n",
    "        8: \"Z40\"\n",
    "    }\n",
    "    for key, value in dictionary.items():\n",
    "        if key == result[0]:\n",
    "            result = value\n",
    "    \n",
    "    predictions.append(result)\n",
    "\n",
    "# Determine the most common prediction and print it as the overall classification of the video\n",
    "most_common_prediction = Counter(predictions).most_common(1)[0][0]\n",
    "print(\"\\nOverall class of the video:\", most_common_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfbdb3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Submitted: unknown.mp4\n",
      "Total frames in the video submitted: 825\n",
      "\n",
      "Overall class of the video: SamsungA23\n"
     ]
    }
   ],
   "source": [
    "testImages = []\n",
    "predictions = []\n",
    "\n",
    "video_path = \"C:/Users/hpvic/Python/VideoForgery/UnseenData/unknown.mp4\"\n",
    "vidcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "video_filename = os.path.basename(video_path) \n",
    "print(\"Video Submitted:\", video_filename)  # Display the video path\n",
    "\n",
    "frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"Total frames in the video submitted:\", frameCount) # Display total number of frames\n",
    "\n",
    "for frameIndex in range(frameCount):\n",
    "    # Set the position of the video to the start of the frame\n",
    "    vidcap.set(cv2.CAP_PROP_POS_FRAMES, frameIndex)\n",
    "\n",
    "    # Read the frame\n",
    "    success, image = vidcap.read()\n",
    "    if not success:\n",
    "        print(\"Error reading frame.\")\n",
    "        continue\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.resize(image, (1920, 1080), interpolation=cv2.INTER_LINEAR)\n",
    "    image = cv2.fastNlMeansDenoising(image, None, 10, 7, 21)\n",
    "\n",
    "    # Append the image to the testImages array\n",
    "    testImages.append(image)\n",
    "\n",
    "# Reshape the images for prediction\n",
    "combine = np.array(testImages)\n",
    "combine = combine.reshape(combine.shape[0], combine.shape[1] * combine.shape[2])\n",
    "\n",
    "# Classify each image and append its class to the predictions array\n",
    "for i in range(len(combine)):\n",
    "    result = loaded_model.predict([combine[i]])\n",
    "    dictionary = {\n",
    "        0: \"70mai A400s\",\n",
    "        1: \"70mai A500s\",\n",
    "        2: \"A800s\",\n",
    "        3: \"D08\",\n",
    "        4: \"HuaweiNova3i\",\n",
    "        5: \"Iphone12ProMax\",\n",
    "        6: \"N3Pro\",\n",
    "        7: \"SamsungA23\",\n",
    "        8: \"Z40\"\n",
    "    }\n",
    "    for key, value in dictionary.items():\n",
    "        if key == result[0]:\n",
    "            result = value\n",
    "    \n",
    "    predictions.append(result)\n",
    "\n",
    "# Determine the most common prediction and print it as the overall classification of the video\n",
    "most_common_prediction = Counter(predictions).most_common(1)[0][0]\n",
    "print(\"\\nOverall class of the video:\", most_common_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d651ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Submitted: UnseenData2.mp4\n",
      "Total frames in the video submitted: 305\n",
      "\n",
      "Overall class of the video: Iphone12ProMax\n"
     ]
    }
   ],
   "source": [
    "testImages = []\n",
    "predictions = []\n",
    "\n",
    "video_path = \"C:/Users/hpvic/Python/VideoForgery/UnseenData/UnseenData2.mp4\"\n",
    "vidcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "video_filename = os.path.basename(video_path) \n",
    "print(\"Video Submitted:\", video_filename)  # Display the video path\n",
    "\n",
    "frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"Total frames in the video submitted:\", frameCount) # Display total number of frames\n",
    "\n",
    "for frameIndex in range(frameCount):\n",
    "    # Set the position of the video to the start of the frame\n",
    "    vidcap.set(cv2.CAP_PROP_POS_FRAMES, frameIndex)\n",
    "\n",
    "    # Read the frame\n",
    "    success, image = vidcap.read()\n",
    "    if not success:\n",
    "        print(\"Error reading frame.\")\n",
    "        continue\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.resize(image, (1920, 1080), interpolation=cv2.INTER_LINEAR)\n",
    "    image = cv2.fastNlMeansDenoising(image, None, 10, 7, 21)\n",
    "\n",
    "    # Append the image to the testImages array\n",
    "    testImages.append(image)\n",
    "\n",
    "# Reshape the images for prediction\n",
    "combine = np.array(testImages)\n",
    "combine = combine.reshape(combine.shape[0], combine.shape[1] * combine.shape[2])\n",
    "\n",
    "# Classify each image and append its class to the predictions array\n",
    "for i in range(len(combine)):\n",
    "    result = loaded_model.predict([combine[i]])\n",
    "    dictionary = {\n",
    "        0: \"70mai A400s\",\n",
    "        1: \"70mai A500s\",\n",
    "        2: \"A800s\",\n",
    "        3: \"D08\",\n",
    "        4: \"HuaweiNova3i\",\n",
    "        5: \"Iphone12ProMax\",\n",
    "        6: \"N3Pro\",\n",
    "        7: \"SamsungA23\",\n",
    "        8: \"Z40\"\n",
    "    }\n",
    "    for key, value in dictionary.items():\n",
    "        if key == result[0]:\n",
    "            result = value\n",
    "    \n",
    "    predictions.append(result)\n",
    "\n",
    "# Determine the most common prediction and print it as the overall classification of the video\n",
    "most_common_prediction = Counter(predictions).most_common(1)[0][0]\n",
    "print(\"\\nOverall class of the video:\", most_common_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
